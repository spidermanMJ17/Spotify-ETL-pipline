{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Welcome to the Glue Interactive Sessions Kernel\n",
						"For more information on available magic commands, please type %help in any new cell.\n",
						"\n",
						"Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n",
						"Installed kernel version: 1.0.8 \n",
						"Current idle_timeout is None minutes.\n",
						"idle_timeout has been set to 2880 minutes.\n",
						"Setting Glue version to: 5.0\n",
						"Previous worker type: None\n",
						"Setting new worker type to: G.1X\n",
						"Previous number of workers: None\n",
						"Setting new number of workers to: 5\n",
						"Trying to create a Glue session for the kernel.\n",
						"Session Type: glueetl\n",
						"Worker Type: G.1X\n",
						"Number of Workers: 5\n",
						"Idle Timeout: 2880\n",
						"Session ID: 5a72bb77-7e0e-44b5-81be-a8bbb95720b4\n",
						"Applying the following default arguments:\n",
						"--glue_kernel_version 1.0.8\n",
						"--enable-glue-datacatalog true\n",
						"Waiting for session 5a72bb77-7e0e-44b5-81be-a8bbb95720b4 to get into ready status...\n",
						"Session 5a72bb77-7e0e-44b5-81be-a8bbb95720b4 has been created.\n",
						"\n"
					]
				}
			],
			"source": [
				"# Set by-default AWS Glue job parameters\n",
				"%idle_timeout 2880\n",
				"%glue_version 5.0\n",
				"%worker_type G.1X\n",
				"%number_of_workers 5\n",
				"\n",
				"# import necessary libraries\n",
				"import sys\n",
				"from awsglue.transforms import *\n",
				"from awsglue.utils import getResolvedOptions\n",
				"from pyspark.context import SparkContext\n",
				"from awsglue.context import GlueContext\n",
				"from awsglue.job import Job\n",
				"\n",
				"# Initialize Glue context and Spark session \n",
				"sc = SparkContext.getOrCreate()\n",
				"glueContext = GlueContext(sc)\n",
				"spark = glueContext.spark_session\n",
				"job = Job(glueContext)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# import additional libraries\n",
				"from pyspark.sql.functions import explode, col, to_date, to_timestamp\n",
				"from datetime import datetime\n",
				"from awsglue.dynamicframe import DynamicFrame\n",
				"import boto3"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Set the S3 path for the source data and create a DynamicFrame\n",
				"s3_path = \"s3://spotify-etl-project-sannu/raw_data/to_process/\"\n",
				"source_dyf = glueContext.create_dynamic_frame_from_options(\n",
				"    connection_type=\"s3\",\n",
				"    connection_options={\"paths\":[s3_path]},\n",
				"    format=\"json\",\n",
				"    format_options={\"jsonPath\": \"$[*]\"}\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n"
					]
				}
			],
			"source": [
				"# Convert DynamicFrame to DataFrame for further processing\n",
				"spotify_df = source_dyf.toDF()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Extract and transform the DataFrame to get track information\n",
				"album_df = spotify_df.select(col(\"track.album.id\").alias(\"album_id\"),\n",
				"                  col(\"track.album.name\").alias(\"album_name\"),\n",
				"                  col(\"track.album.release_date\").alias(\"album_release_date\"),\n",
				"                  col(\"track.album.total_tracks\").alias(\"album_total_tracks\"),\n",
				"                  col(\"track.album.external_urls.spotify\").alias(\"album_url\"),\n",
				"                 ).drop_duplicates([\"album_id\"])"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Convert the release date to a date format\n",
				"album_df = album_df.withColumn(\n",
				"    \"album_release_date\",\n",
				"    to_date(\"album_release_date\", \"yyyy-MM-dd\")\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Extract and transform the DataFrame to get artist information\n",
				"artist_df = spotify_df.select(col(\"track.artists\"))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Explode the artists array to create a row for each artist\n",
				"artist_df = artist_df.withColumn(\"artist\",explode(\"artists\"))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Select relevant artist fields and drop duplicates\n",
				"artist_df = artist_df.select(col(\"artist.id\").alias(\"artist_id\"),\n",
				"                  col(\"artist.name\").alias(\"artist_name\"),\n",
				"                  col(\"artist.external_urls.spotify\").alias(\"external_url\"),\n",
				"                 ).drop_duplicates([\"artist_id\"])"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Extract and transform the DataFrame to get song information\n",
				"songs_df = spotify_df.select(\n",
				"                  col(\"track.id\").alias(\"song_id\"),\n",
				"                  col(\"track.name\").alias(\"song_name\"),\n",
				"                  col(\"track.duration_ms\").alias(\"duration_ms\"),\n",
				"                  col(\"track.external_urls.spotify\").alias(\"url\"),\n",
				"                  col(\"track.popularity\").alias(\"popularity\"),\n",
				"                  col(\"added_at\").alias(\"song_added\"),\n",
				"                  col(\"track.album.id\").alias(\"album_id\"),\n",
				"                  col(\"track.artists\")\n",
				"                 ).drop_duplicates([\"song_id\"])"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Explode the artists array to create a row for each artist\n",
				"songs_df = songs_df.withColumn(\"artists\", explode(\"artists\")).withColumn(\"artists\", col(\"artists.id\"))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Rename the artists column to artist_id for clarity\n",
				"songs_df = songs_df.withColumnRenamed(\"artists\", \"artist_id\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Convert the song_added timestamp to a proper timestamp format\n",
				"songs_df = songs_df.withColumn(\n",
				"    \"song_added\",\n",
				"    to_timestamp(\"song_added\", \"yyyy-MM-dd'T'HH:mm:ss'Z'\")\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Function to write DataFrame to S3 in the specified format\n",
				"def write_to_s3(df, path_suffix, format_type=\"csv\"):\n",
				"    dynamic_frame = DynamicFrame.fromDF(df, glueContext, \"dynamic_frame\")\n",
				"    \n",
				"    glueContext.write_dynamic_frame.from_options(\n",
				"        frame = dynamic_frame,\n",
				"        connection_type = \"s3\",\n",
				"        connection_options = {\"path\": f\"s3://spotify-etl-project-sannu/transformed_data/{path_suffix}/\"},\n",
				"        format = format_type\n",
				"    )"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Generate a timestamp for the output files\n",
				"timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S-%f\")\n",
				"\n",
				"# Write the transformed DataFrames to S3\n",
				"write_to_s3(album_df, f\"album/album_transformed_{timestamp}\", \"csv\")\n",
				"write_to_s3(artist_df, f\"artist/artist_transformed_{timestamp}\", \"csv\")\n",
				"write_to_s3(songs_df, f\"songs/song_transformed_{timestamp}\", \"csv\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Initialize the S3 client to list files\n",
				"s3 = boto3.client('s3')\n",
				"Bucket = \"spotify-etl-project-sannu\"\n",
				"Key = \"raw_data/to_process/\"\n",
				"\n",
				"# List all JSON files in the specified S3 bucket and prefix \n",
				"spotify_keys = []\n",
				"for file in s3.list_objects(Bucket=Bucket, Prefix=Key)['Contents']:\n",
				"    file_key = file['Key']\n",
				"    if file_key.split('.')[-1] == \"json\":\n",
				"        spotify_keys.append(file_key)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"{'ResponseMetadata': {'RequestId': 'KRQZ940X13MX6YHX', 'HostId': 'V890iP6dnoKqxc1RjTY1+Ua2Gyi85ICAus9WuR/PJgA5eQxylg4F6xJBr5AMyyT6u8Txe0sS4Roz0keXMaVOaw==', 'HTTPStatusCode': 204, 'HTTPHeaders': {'x-amz-id-2': 'V890iP6dnoKqxc1RjTY1+Ua2Gyi85ICAus9WuR/PJgA5eQxylg4F6xJBr5AMyyT6u8Txe0sS4Roz0keXMaVOaw==', 'x-amz-request-id': 'KRQZ940X13MX6YHX', 'date': 'Fri, 11 Jul 2025 12:30:38 GMT', 'server': 'AmazonS3'}, 'RetryAttempts': 0}}\n"
					]
				}
			],
			"source": [
				"# Copy the processed files to the new location and delete the original files\n",
				"s3_resource = boto3.resource('s3')\n",
				"for key in spotify_keys:\n",
				"    copy_source = {\n",
				"        'Bucket': Bucket,\n",
				"        'Key': key\n",
				"    }\n",
				"    s3_resource.meta.client.copy(copy_source, Bucket, 'raw_data/processed/' + key.split(\"/\")[-1])    \n",
				"    s3_resource.Object(Bucket, key).delete()"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"pygments_lexer": "python3",
			"version": "3.12.2"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
